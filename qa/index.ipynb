{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python tf-models-official \"tensorflow-text==2.9.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!cp -r /content/drive/MyDrive/ml/* ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据量中间计算量过大，将训练数据转换成TFRecord。省去中间重复计算（tokenid,typeid,mkid）的时间。\n",
    "# !git clone https://github.com/tensorflow/models.git\n",
    "# !python3 models/official/nlp/data/create_finetuning_data.py \\\n",
    "#  --squad_data_file=/content/squad/train-v2.0.json \\\n",
    "#  --vocab_file=gs://cloud-tpu-checkpoints/bert/v3/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "#  --train_data_output_path=/content/squad/train_v2.0.tf_record \\\n",
    "#  --meta_data_file_path=/content/squad/squad_v2.0_meta_data \\\n",
    "#  --fine_tuning_task_type=squad \\\n",
    "#  --max_seq_length=384 \\\n",
    "#  --version_2_with_negative=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow_models import nlp\n",
    "from keras import metrics, layers, optimizers, losses, Model\n",
    "from keras.utils import plot_model\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_folder_bert = \"gs://cloud-tpu-checkpoints/bert/v3/uncased_L-12_H-768_A-12\"\n",
    "tf.io.gfile.listdir(gs_folder_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_dir = \"/content\"\n",
    "bert_dir = gs_folder_bert\n",
    "squad_version = \"v2.0\"\n",
    "squad_dir = database_dir+\"/squad\"\n",
    "max_seq_length = 384\n",
    "train_batch_size = 12\n",
    "train_epochs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = tf.data.TFRecordDataset([os.path.join(\n",
    "    squad_dir, f\"train_{squad_version}.tf_record\")])\n",
    "\n",
    "feature_description = {\n",
    "    'unique_ids': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'input_ids': tf.io.FixedLenFeature(shape=(max_seq_length,), dtype=tf.int64, default_value=[0] * max_seq_length),\n",
    "    'input_mask': tf.io.FixedLenFeature(shape=(max_seq_length,), dtype=tf.int64, default_value=[0] * max_seq_length),\n",
    "    'segment_ids': tf.io.FixedLenFeature(shape=(max_seq_length,), dtype=tf.int64, default_value=[0] * max_seq_length),\n",
    "    'paragraph_mask': tf.io.FixedLenFeature(shape=(max_seq_length,), dtype=tf.int64, default_value=[0] * max_seq_length),\n",
    "    'class_index': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'start_positions': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'end_positions': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'is_impossible': tf.io.FixedLenFeature([], tf.int64, default_value=0)\n",
    "}\n",
    "\n",
    "def decode_fn(record_bytes):\n",
    "    example = tf.io.parse_single_example(\n",
    "        record_bytes,\n",
    "        feature_description\n",
    "    )\n",
    "    # example[\"input_word_ids\"] = example[\"input_ids\"]\n",
    "    # example[\"input_type_ids\"] = example[\"segment_ids\"]\n",
    "\n",
    "    return {\n",
    "        'input_word_ids': example[\"input_ids\"],\n",
    "        'input_type_ids': example[\"segment_ids\"],\n",
    "        'input_mask': example[\"input_mask\"],\n",
    "        'is_impossible': example[\"is_impossible\"]\n",
    "    }, {\n",
    "        \"start_positions\": example[\"start_positions\"],\n",
    "        \"end_positions\": example[\"end_positions\"],\n",
    "    }\n",
    "\n",
    "\n",
    "# for raw_record in raw_dataset.take(10).map(decode_fn):\n",
    "#     print(raw_record)\n",
    "\n",
    "bert_config_file = os.path.join(bert_dir, 'bert_config.json')\n",
    "config_dict = json.loads(tf.io.gfile.GFile(bert_config_file).read())\n",
    "\n",
    "dataset = raw_dataset.shuffle(buffer_size=train_batch_size).map(decode_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 总条目131944,可用条目87212\n",
    "train_num = 70000\n",
    "\n",
    "dataset = dataset.filter(lambda x, y: x['is_impossible'] == 0)\n",
    "\n",
    "train_ds = dataset.take(train_num).batch(batch_size=train_batch_size)\n",
    "\n",
    "test_ds = dataset.skip(train_num).batch(batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_config = nlp.encoders.EncoderConfig({\n",
    "    'type': 'bert',\n",
    "    'bert': config_dict\n",
    "})\n",
    "\n",
    "bert_encoder = nlp.encoders.build_encoder(encoder_config)\n",
    "\n",
    "bert_span = nlp.models.BertSpanLabeler(network=bert_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(bert_span, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.train.Checkpoint(encoder=bert_encoder)\n",
    "\n",
    "checkpoint.read(\n",
    "    os.path.join(bert_dir, 'bert_model.ckpt')\n",
    ").assert_consumed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_span.compile(optimizer='adam',\n",
    "                  loss={\n",
    "                      'start_positions': 'sparse_categorical_crossentropy',\n",
    "                      'end_positions': 'sparse_categorical_crossentropy'\n",
    "                  },\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_span.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_span.fit(train_ds,\n",
    "              validation_data=(test_ds),\n",
    "              batch_size=train_batch_size,\n",
    "              epochs=train_epochs)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
